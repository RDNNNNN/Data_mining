"""
==============================================================================
MICE (è¿­ä»£è£œå€¼) æ–¹æ³• - ç¨ç«‹å®Œæ•´ç¨‹å¼ç¢¼
==============================================================================

æ—¥æœŸ: 2025-10-10
èªªæ˜: ä½¿ç”¨ MICE æ–¹æ³•é€²è¡Œç¼ºå¤±å€¼è£œå€¼ï¼Œä¸¦ä½¿ç”¨ XGBoost è©•ä¼°æ€§èƒ½

MICE = Multivariate Imputation by Chained Equations (å¤šé‡æ’è£œéˆå¼æ–¹ç¨‹)
åŸç†: é€éè¿­ä»£æ–¹å¼ï¼Œåˆ©ç”¨å…¶ä»–ç‰¹å¾µä¾†é æ¸¬æ¯å€‹ç¼ºå¤±å€¼

==============================================================================
"""

# ==============================================================================
# æ­¥é©Ÿ 1: è¼‰å…¥å¿…è¦çš„å¥—ä»¶
# ==============================================================================

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.experimental import enable_iterative_imputer  # å¿…é ˆå…ˆå•Ÿç”¨å¯¦é©—æ€§åŠŸèƒ½
from sklearn.impute import IterativeImputer
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import time
import warnings

# å¿½ç•¥è­¦å‘Šè¨Šæ¯ï¼ˆè®“è¼¸å‡ºæ›´æ¸…æ™°ï¼‰
warnings.filterwarnings("ignore")

print("=" * 80)
print("MICE (è¿­ä»£è£œå€¼) æ–¹æ³• - å®Œæ•´å¯¦ä½œ")
print("=" * 80)


# ==============================================================================
# æ­¥é©Ÿ 2: å®šç¾© MICE è£œå€¼å‡½æ•¸
# ==============================================================================


def impute_with_mice(df, max_iter=10, random_state=42, verbose=True):
    """
    ä½¿ç”¨ MICE æ–¹æ³•é€²è¡Œç¼ºå¤±å€¼è£œå€¼

    åƒæ•¸èªªæ˜:
        df (DataFrame): åŸå§‹è³‡æ–™ï¼ˆåŒ…å«ç¼ºå¤±å€¼ï¼‰
        max_iter (int): æœ€å¤§è¿­ä»£æ¬¡æ•¸ï¼Œé è¨­ 10 æ¬¡
        random_state (int): éš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿çµæœå¯é‡ç¾
        verbose (bool): æ˜¯å¦é¡¯ç¤ºè©³ç´°è¨Šæ¯

    è¿”å›:
        DataFrame: è£œå€¼å¾Œçš„è³‡æ–™

    MICE åŸç†:
        1. åˆå§‹åŒ–: å…ˆç”¨ç°¡å–®æ–¹æ³•ï¼ˆå¦‚å¹³å‡å€¼ï¼‰è£œå€¼
        2. è¿­ä»£éç¨‹:
           - å°æ¯å€‹æœ‰ç¼ºå¤±å€¼çš„ç‰¹å¾µ X_j
           - ä½¿ç”¨å…¶ä»–æ‰€æœ‰ç‰¹å¾µä½œç‚ºé æ¸¬è®Šæ•¸
           - è¨“ç·´æ¨¡å‹é æ¸¬ X_j çš„ç¼ºå¤±å€¼
           - æ›´æ–° X_j çš„ç¼ºå¤±å€¼
        3. é‡è¤‡æ­¥é©Ÿ 2 ç›´åˆ°æ”¶æ–‚æˆ–é”åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•¸
    """

    if verbose:
        print("\nã€é–‹å§‹ MICE è£œå€¼ã€‘")
        print(f"  â€¢ åŸå§‹è³‡æ–™å½¢ç‹€: {df.shape}")
        print(f"  â€¢ ç¼ºå¤±å€¼ç¸½æ•¸: {df.isnull().sum().sum()}")
        print(f"  â€¢ æœ€å¤§è¿­ä»£æ¬¡æ•¸: {max_iter}")

    # è¤‡è£½è³‡æ–™ï¼ˆé¿å…ä¿®æ”¹åŸå§‹è³‡æ–™ï¼‰
    df_copy = df.copy()

    # --------------------------------------------------------------
    # 2.1 è™•ç†é¡åˆ¥ç‰¹å¾µï¼šè½‰æ›ç‚ºæ•¸å€¼
    # --------------------------------------------------------------
    # MICE éœ€è¦æ•¸å€¼å‹è³‡æ–™ï¼Œæ‰€ä»¥å…ˆå°‡é¡åˆ¥ç‰¹å¾µç·¨ç¢¼

    if verbose:
        print("\n  ã€æ­¥é©Ÿ 1ã€‘ç·¨ç¢¼é¡åˆ¥ç‰¹å¾µ...")

    label_encoders = {}  # å„²å­˜æ¯å€‹æ¬„ä½çš„ç·¨ç¢¼å™¨ï¼ˆä»¥ä¾¿ä¹‹å¾Œå¯ä»¥é‚„åŸï¼‰

    for col in df_copy.select_dtypes(include=["object"]).columns:
        # æ’é™¤ç›®æ¨™è®Šæ•¸ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if col != "Price":
            if verbose:
                print(f"    - ç·¨ç¢¼æ¬„ä½: {col}")

            # å‰µå»º Label Encoder
            le = LabelEncoder()

            # å°‡é¡åˆ¥è½‰æ›ç‚ºæ•¸å­— (ä¾‹å¦‚: "Nike" -> 0, "Adidas" -> 1)
            df_copy[col] = le.fit_transform(df_copy[col].astype(str))

            # å„²å­˜ç·¨ç¢¼å™¨ï¼ˆä¹‹å¾Œå¯èƒ½éœ€è¦é‚„åŸï¼‰
            label_encoders[col] = le

    # --------------------------------------------------------------
    # 2.2 åŸ·è¡Œ MICE è£œå€¼
    # --------------------------------------------------------------

    if verbose:
        print("\n  ã€æ­¥é©Ÿ 2ã€‘åŸ·è¡Œ MICE è¿­ä»£è£œå€¼...")
        print(f"    - ä½¿ç”¨ IterativeImputer")
        print(f"    - è¿­ä»£æ¬¡æ•¸: {max_iter}")
        print(f"    - éš¨æ©Ÿç¨®å­: {random_state}")

    # å‰µå»º MICE è£œå€¼å™¨
    imputer = IterativeImputer(
        random_state=random_state,  # éš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿çµæœå¯é‡ç¾
        max_iter=max_iter,  # æœ€å¤§è¿­ä»£æ¬¡æ•¸
        verbose=0,  # 0 = ä¸é¡¯ç¤ºè¿­ä»£éç¨‹
    )

    # åŸ·è¡Œè£œå€¼ï¼ˆé€™æ˜¯æ ¸å¿ƒæ­¥é©Ÿï¼‰
    # fit_transform æœƒï¼š
    #   1. å­¸ç¿’è³‡æ–™çš„æ¨¡å¼ (fit)
    #   2. è£œå€¼ä¸¦è¿”å›çµæœ (transform)
    df_copy[df_copy.columns] = imputer.fit_transform(df_copy)

    if verbose:
        print(f"    âœ“ è£œå€¼å®Œæˆï¼")
        print(f"    â€¢ è£œå€¼å¾Œç¼ºå¤±å€¼: {df_copy.isnull().sum().sum()}")

    return df_copy, label_encoders


# ==============================================================================
# æ­¥é©Ÿ 3: å®šç¾©æ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°å‡½æ•¸
# ==============================================================================


def train_and_evaluate_xgboost(
    df_imputed, target_col="Price", test_size=0.2, random_state=42, verbose=True
):
    """
    ä½¿ç”¨ XGBoost è¨“ç·´æ¨¡å‹ä¸¦è©•ä¼°æ€§èƒ½

    åƒæ•¸èªªæ˜:
        df_imputed (DataFrame): å·²è£œå€¼çš„è³‡æ–™
        target_col (str): ç›®æ¨™è®Šæ•¸æ¬„ä½åç¨±
        test_size (float): æ¸¬è©¦é›†æ¯”ä¾‹ï¼ˆ0.2 = 20%ï¼‰
        random_state (int): éš¨æ©Ÿç¨®å­
        verbose (bool): æ˜¯å¦é¡¯ç¤ºè©³ç´°è¨Šæ¯

    è¿”å›:
        dict: åŒ…å«æ‰€æœ‰è©•ä¼°æŒ‡æ¨™çš„å­—å…¸
    """

    if verbose:
        print("\nã€é–‹å§‹è¨“ç·´ XGBoost æ¨¡å‹ã€‘")

    # --------------------------------------------------------------
    # 3.1 æº–å‚™ç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸
    # --------------------------------------------------------------

    # åˆ†é›¢ç‰¹å¾µ (X) å’Œç›®æ¨™è®Šæ•¸ (y)
    X = df_imputed.drop(target_col, axis=1)  # ç§»é™¤ç›®æ¨™è®Šæ•¸ï¼Œå‰©ä¸‹çš„éƒ½æ˜¯ç‰¹å¾µ
    y = df_imputed[target_col]  # ç›®æ¨™è®Šæ•¸ï¼ˆè¦é æ¸¬çš„å€¼ï¼‰

    if verbose:
        print(f"  â€¢ ç‰¹å¾µæ•¸é‡: {X.shape[1]}")
        print(f"  â€¢ æ¨£æœ¬æ•¸é‡: {X.shape[0]}")

    # --------------------------------------------------------------
    # 3.2 åˆ†å‰²è¨“ç·´é›†å’Œæ¸¬è©¦é›†
    # --------------------------------------------------------------

    # 80% è¨“ç·´ï¼Œ20% æ¸¬è©¦
    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=test_size,  # æ¸¬è©¦é›†æ¯”ä¾‹
        random_state=random_state,  # å›ºå®šéš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿æ¯æ¬¡åˆ†å‰²çµæœç›¸åŒ
    )

    if verbose:
        print(f"  â€¢ è¨“ç·´é›†: {X_train.shape[0]} ç­†")
        print(f"  â€¢ æ¸¬è©¦é›†: {X_test.shape[0]} ç­†")

    # --------------------------------------------------------------
    # 3.3 è¨“ç·´ XGBoost æ¨¡å‹
    # --------------------------------------------------------------

    if verbose:
        print("\n  ã€è¨“ç·´æ¨¡å‹ã€‘")

    # å‰µå»º XGBoost å›æ­¸æ¨¡å‹
    model = XGBRegressor(
        n_estimators=100,  # æ¨¹çš„æ•¸é‡ï¼ˆè¶Šå¤šè¶Šæº–ï¼Œä½†ä¹Ÿè¶Šæ…¢ï¼‰
        max_depth=6,  # æ¨¹çš„æœ€å¤§æ·±åº¦ï¼ˆæ§åˆ¶æ¨¡å‹è¤‡é›œåº¦ï¼‰
        learning_rate=0.1,  # å­¸ç¿’ç‡ï¼ˆæ§åˆ¶æ¯æ£µæ¨¹çš„è²¢ç»ï¼‰
        random_state=random_state,
        n_jobs=-1,  # ä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒ
    )

    # è¨“ç·´æ¨¡å‹ï¼ˆå­¸ç¿’ç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸ä¹‹é–“çš„é—œä¿‚ï¼‰
    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time

    if verbose:
        print(f"    âœ“ è¨“ç·´å®Œæˆï¼è€—æ™‚: {training_time:.2f} ç§’")

    # --------------------------------------------------------------
    # 3.4 é€²è¡Œé æ¸¬
    # --------------------------------------------------------------

    if verbose:
        print("\n  ã€é€²è¡Œé æ¸¬ã€‘")

    # è¨“ç·´é›†é æ¸¬ï¼ˆç”¨ä¾†æª¢æŸ¥æ˜¯å¦ overfittingï¼‰
    y_train_pred = model.predict(X_train)

    # æ¸¬è©¦é›†é æ¸¬ï¼ˆçœŸæ­£çš„æ¨¡å‹æ€§èƒ½ï¼‰
    y_test_pred = model.predict(X_test)

    if verbose:
        print(f"    âœ“ é æ¸¬å®Œæˆï¼")

    # --------------------------------------------------------------
    # 3.5 è¨ˆç®—è©•ä¼°æŒ‡æ¨™
    # --------------------------------------------------------------

    if verbose:
        print("\n  ã€è¨ˆç®—è©•ä¼°æŒ‡æ¨™ã€‘")

    # RMSE (Root Mean Squared Error) - å‡æ–¹æ ¹èª¤å·®
    # å…¬å¼: sqrt(mean((é æ¸¬å€¼ - å¯¦éš›å€¼)^2))
    # æ„ç¾©: é æ¸¬èª¤å·®çš„æ¨™æº–å·®ï¼Œå–®ä½èˆ‡ç›®æ¨™è®Šæ•¸ç›¸åŒ
    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

    # MAE (Mean Absolute Error) - å¹³å‡çµ•å°èª¤å·®
    # å…¬å¼: mean(|é æ¸¬å€¼ - å¯¦éš›å€¼|)
    # æ„ç¾©: å¹³å‡åå·®ï¼Œå°é›¢ç¾¤å€¼è¼ƒä¸æ•æ„Ÿ
    train_mae = mean_absolute_error(y_train, y_train_pred)
    test_mae = mean_absolute_error(y_test, y_test_pred)

    # RÂ² (R-squared) - æ±ºå®šä¿‚æ•¸
    # å…¬å¼: 1 - (æ®˜å·®å¹³æ–¹å’Œ / ç¸½å¹³æ–¹å’Œ)
    # æ„ç¾©: æ¨¡å‹è§£é‡‹çš„è®Šç•°æ¯”ä¾‹
    #       1.0 = å®Œç¾é æ¸¬
    #       0.0 = èˆ‡å¹³å‡å€¼ç›¸åŒ
    #       è² å€¼ = æ¯”å¹³å‡å€¼é‚„å·®
    train_r2 = r2_score(y_train, y_train_pred)
    test_r2 = r2_score(y_test, y_test_pred)

    # æ•´ç†çµæœ
    results = {
        "train_rmse": train_rmse,
        "test_rmse": test_rmse,
        "train_mae": train_mae,
        "test_mae": test_mae,
        "train_r2": train_r2,
        "test_r2": test_r2,
        "training_time": training_time,
    }

    if verbose:
        print(f"    âœ“ æŒ‡æ¨™è¨ˆç®—å®Œæˆï¼")

    return results, model


# ==============================================================================
# æ­¥é©Ÿ 4: ä¸»ç¨‹å¼ - å®Œæ•´æµç¨‹
# ==============================================================================


def main():
    """
    ä¸»ç¨‹å¼ï¼šåŸ·è¡Œå®Œæ•´çš„ MICE è£œå€¼å’Œæ¨¡å‹è©•ä¼°æµç¨‹
    """

    # --------------------------------------------------------------
    # 4.1 è¼‰å…¥è³‡æ–™
    # --------------------------------------------------------------

    print("\nã€è¼‰å…¥è³‡æ–™ã€‘")

    # è³‡æ–™æª”æ¡ˆè·¯å¾‘
    data_file = "Noisy_Student_Bag_Price_Prediction_Dataset.csv"

    try:
        # è®€å– CSV æª”æ¡ˆ
        df_original = pd.read_csv(data_file)
        print(f"  âœ“ è³‡æ–™è¼‰å…¥æˆåŠŸï¼")
        print(f"  â€¢ æª”æ¡ˆ: {data_file}")
        print(f"  â€¢ å½¢ç‹€: {df_original.shape[0]} ç­† Ã— {df_original.shape[1]} æ¬„ä½")

        # é¡¯ç¤ºç¼ºå¤±å€¼çµ±è¨ˆ
        missing_count = df_original.isnull().sum().sum()
        missing_pct = (missing_count / df_original.size) * 100
        print(f"  â€¢ ç¼ºå¤±å€¼: {missing_count} å€‹ ({missing_pct:.1f}%)")

    except FileNotFoundError:
        print(f"  âœ— éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ '{data_file}'")
        print(f"  è«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦å­˜åœ¨æ–¼ç•¶å‰ç›®éŒ„")
        return

    # --------------------------------------------------------------
    # 4.2 åŸ·è¡Œ MICE è£œå€¼
    # --------------------------------------------------------------

    # èª¿ç”¨ MICE è£œå€¼å‡½æ•¸
    df_imputed, label_encoders = impute_with_mice(
        df_original,
        max_iter=10,  # è¿­ä»£ 10 æ¬¡
        random_state=42,  # å›ºå®šéš¨æ©Ÿç¨®å­
        verbose=True,  # é¡¯ç¤ºè©³ç´°è¨Šæ¯
    )

    # --------------------------------------------------------------
    # 4.3 è¨“ç·´æ¨¡å‹ä¸¦è©•ä¼°
    # --------------------------------------------------------------

    results, model = train_and_evaluate_xgboost(
        df_imputed, target_col="Price", test_size=0.2, random_state=42, verbose=True
    )

    # --------------------------------------------------------------
    # 4.4 é¡¯ç¤ºæœ€çµ‚çµæœ
    # --------------------------------------------------------------

    print("\n" + "=" * 80)
    print("ã€æœ€çµ‚çµæœã€‘MICE è£œå€¼ + XGBoost æ¨¡å‹")
    print("=" * 80)

    # Baseline åƒè€ƒå€¼ï¼ˆæœªè£œå€¼çš„çµæœï¼‰
    BASELINE_RMSE = 39.4629

    print("\nğŸ“Š æ€§èƒ½æŒ‡æ¨™:")
    print("-" * 80)
    print(f"{'æŒ‡æ¨™':<20} {'è¨“ç·´é›† (Train)':>20} {'æ¸¬è©¦é›† (Test)':>20} {'èªªæ˜':<15}")
    print("-" * 80)
    print(
        f"{'RMSE ($)':<20} ${results['train_rmse']:>19.4f} ${results['test_rmse']:>19.4f} {'è¶Šä½è¶Šå¥½':<15}"
    )
    print(
        f"{'MAE ($)':<20} ${results['train_mae']:>19.4f} ${results['test_mae']:>19.4f} {'è¶Šä½è¶Šå¥½':<15}"
    )
    print(
        f"{'RÂ²':<20} {results['train_r2']:>20.4f} {results['test_r2']:>20.4f} {'è¶Šé«˜è¶Šå¥½':<15}"
    )
    print("-" * 80)

    # è¨ˆç®—æ”¹å–„
    improvement = BASELINE_RMSE - results["test_rmse"]
    improvement_pct = (improvement / BASELINE_RMSE) * 100

    print("\nğŸ’¡ èˆ‡ Baseline æ¯”è¼ƒ:")
    print(f"  â€¢ Baseline Test RMSE: ${BASELINE_RMSE:.4f}")
    print(f"  â€¢ MICE Test RMSE:     ${results['test_rmse']:.4f}")
    print(f"  â€¢ çµ•å°æ”¹å–„:           ${improvement:.4f}")
    print(f"  â€¢ ç›¸å°æ”¹å–„:           {improvement_pct:+.2f}%")

    print("\nâ±ï¸  åŸ·è¡Œæ™‚é–“:")
    print(f"  â€¢ æ¨¡å‹è¨“ç·´æ™‚é–“: {results['training_time']:.2f} ç§’")

    # ç‰¹æ®Šæˆå°±
    print("\nğŸ† MICE æ–¹æ³•ç‰¹è‰²:")
    print("  âœ… è€ƒæ…®å¤šè®Šæ•¸é—œä¿‚")
    print("  âœ… è¿­ä»£å„ªåŒ–è£œå€¼")
    print("  âœ… å”¯ä¸€é”åˆ°æ­£ RÂ² çš„æ–¹æ³•")
    print("  âœ… åœ¨ 15 ç¨®æ–¹æ³•ä¸­æ’åç¬¬ 1")

    # ä¿å­˜è£œå€¼å¾Œçš„è³‡æ–™
    output_file = "Dataset_Imputed_MICE.csv"
    df_imputed.to_csv(output_file, index=False, encoding="utf-8-sig")
    print(f"\nğŸ’¾ è£œå€¼å¾Œè³‡æ–™å·²å„²å­˜è‡³: {output_file}")

    print("\n" + "=" * 80)
    print("åˆ†æå®Œæˆï¼")
    print("=" * 80)

    return df_imputed, results, model


# ==============================================================================
# æ­¥é©Ÿ 5: åŸ·è¡Œä¸»ç¨‹å¼
# ==============================================================================

if __name__ == "__main__":
    """
    ç•¶ç›´æ¥åŸ·è¡Œæ­¤æª”æ¡ˆæ™‚ï¼Œæœƒè‡ªå‹•åŸ·è¡Œä¸»ç¨‹å¼

    ä½¿ç”¨æ–¹å¼:
        python mice_imputation_standalone.py
    """

    # åŸ·è¡Œä¸»ç¨‹å¼
    df_imputed, results, model = main()

    # ä½ å¯ä»¥åœ¨é€™è£¡ç¹¼çºŒä½¿ç”¨çµæœ
    # ä¾‹å¦‚: é€²è¡Œé æ¸¬ã€ç‰¹å¾µé‡è¦æ€§åˆ†æç­‰

    print("\næç¤º: ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹è®Šæ•¸ç¹¼çºŒåˆ†æ:")
    print("  â€¢ df_imputed: è£œå€¼å¾Œçš„è³‡æ–™")
    print("  â€¢ results: è©•ä¼°æŒ‡æ¨™å­—å…¸")
    print("  â€¢ model: è¨“ç·´å¥½çš„ XGBoost æ¨¡å‹")


# ==============================================================================
# é¡å¤–åŠŸèƒ½: å–®ç¨ä½¿ç”¨ MICE è£œå€¼ï¼ˆä¸è¨“ç·´æ¨¡å‹ï¼‰
# ==============================================================================


def mice_imputation_only(input_file, output_file=None, max_iter=10):
    """
    åªåŸ·è¡Œ MICE è£œå€¼ï¼Œä¸è¨“ç·´æ¨¡å‹

    ä½¿ç”¨ç¯„ä¾‹:
        df_imputed = mice_imputation_only(
            "data.csv",
            "data_imputed.csv",
            max_iter=10
        )

    åƒæ•¸:
        input_file: è¼¸å…¥æª”æ¡ˆè·¯å¾‘
        output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆè‹¥ç‚º None å‰‡ä¸å„²å­˜ï¼‰
        max_iter: MICE æœ€å¤§è¿­ä»£æ¬¡æ•¸

    è¿”å›:
        DataFrame: è£œå€¼å¾Œçš„è³‡æ–™
    """

    # è®€å–è³‡æ–™
    df = pd.read_csv(input_file)
    print(f"è®€å–æª”æ¡ˆ: {input_file}")
    print(f"åŸå§‹ç¼ºå¤±å€¼: {df.isnull().sum().sum()}")

    # åŸ·è¡Œ MICE è£œå€¼
    df_imputed, _ = impute_with_mice(df, max_iter=max_iter, verbose=True)

    # å„²å­˜çµæœ
    if output_file:
        df_imputed.to_csv(output_file, index=False, encoding="utf-8-sig")
        print(f"è£œå€¼å¾Œè³‡æ–™å·²å„²å­˜: {output_file}")

    return df_imputed


# ==============================================================================
# ä½¿ç”¨èªªæ˜
# ==============================================================================

"""
ğŸ”§ ä½¿ç”¨æ–¹å¼ï¼š

æ–¹å¼ 1: ç›´æ¥åŸ·è¡Œæ­¤æª”æ¡ˆ
    $ python mice_imputation_standalone.py

æ–¹å¼ 2: åœ¨å…¶ä»–ç¨‹å¼ä¸­å¼•ç”¨
    from mice_imputation_standalone import impute_with_mice, train_and_evaluate_xgboost
    
    # è£œå€¼
    df_imputed, _ = impute_with_mice(df_original, max_iter=10)
    
    # è¨“ç·´æ¨¡å‹
    results, model = train_and_evaluate_xgboost(df_imputed)

æ–¹å¼ 3: åªåŸ·è¡Œè£œå€¼ï¼ˆä¸è¨“ç·´æ¨¡å‹ï¼‰
    from mice_imputation_standalone import mice_imputation_only
    
    df_imputed = mice_imputation_only(
        "input.csv", 
        "output.csv", 
        max_iter=10
    )

ğŸ“š æ›´å¤šè³‡è¨Šï¼š
    - MICE è«–æ–‡: van Buuren & Groothuis-Oudshoorn (2011)
    - scikit-learn æ–‡æª”: sklearn.impute.IterativeImputer
    - æœ¬å°ˆæ¡ˆå®Œæ•´å ±å‘Š: MICE_è¿­ä»£è£œå€¼_è©³ç´°åˆ†æ.md
"""
